{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8005778a",
   "metadata": {},
   "source": [
    "# A Tutorial on Community Models and Integrations - PhysicsNeMo\n",
    "\n",
    "In this tutorial, PhysicsNeMo is used to expand the scope of community models and datasets, such as [The Well](https://github.com/PolymathicAI/the_well) by leveraging physics informed utilities, optimized model layers, and MLOps best practices. Specifically, the tutorial covers:\n",
    ". Loading and evaluating a checkpoint from `The Well` \n",
    ". How to use a pretrained checkpoint from `The Well` and run it as a PhysicsNeMo user\n",
    ". Training community models with PhysicsNeMo\n",
    ". Fine-tuning community models with PhysicsNeMo\n",
    ". Experimenting with different architectures, from the community and internal to PhysicsNeMo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa944336",
   "metadata": {},
   "source": [
    "## Loading Models and Data from `The Well`\n",
    "\n",
    "To begin, a model and dataset from `the_well` is selected for use throughout this example. For this example, the [Magnetohydrodynamics dataset](https://github.com/PolymathicAI/the_well/tree/master/datasets/MHD_64) is used. Magnetohydrodynamics (MHD), is the study of the dynamics of electrically conducting fluids such as plasmas.\n",
    "\n",
    "Note that any one of the models and dataset combinations may be selected.\n",
    "\n",
    "In addition to the data, a pre-trained model with a Tucker-Factorized Fourier Neural Operator (TFNO) architecture is used that will be later converted to PhysicsNeMo.\n",
    "\n",
    "The dataset streaming functionality from `the_well` will be utilized so that the dataset does not need to be downloaded locally. This requires accessing huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affec459",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf33afb9cb544b0a6e5ea8c1f70b106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f273c6ad864381ba4b81d724390328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "TFNO                                                    --\n",
       "├─NeuralOpsCheckpointWrapper: 1-1                       --\n",
       "│    └─FNOBlocks: 2-1                                   --\n",
       "│    │    └─SpectralConv: 3-1                           512\n",
       "│    │    │    └─ModuleList: 4-1                        --\n",
       "│    │    │    │    └─ComplexTuckerTensor: 5-1          75,564,194\n",
       "│    │    │    │    └─ComplexTuckerTensor: 5-2          75,564,194\n",
       "│    │    │    │    └─ComplexTuckerTensor: 5-3          75,564,194\n",
       "│    │    │    │    └─ComplexTuckerTensor: 5-4          75,564,194\n",
       "│    │    └─ModuleList: 3-2                             --\n",
       "│    │    │    └─Conv3d: 4-2                            16,384\n",
       "│    │    │    └─Conv3d: 4-3                            16,384\n",
       "│    │    │    └─Conv3d: 4-4                            16,384\n",
       "│    │    │    └─Conv3d: 4-5                            16,384\n",
       "│    └─MLP: 2-2                                         --\n",
       "│    │    └─ModuleList: 3-3                             --\n",
       "│    │    │    └─Conv3d: 4-6                            7,424\n",
       "│    │    │    └─Conv3d: 4-7                            32,896\n",
       "│    └─MLP: 2-3                                         --\n",
       "│    │    └─ModuleList: 3-4                             --\n",
       "│    │    │    └─Conv3d: 4-8                            33,024\n",
       "│    │    │    └─Conv3d: 4-9                            1,799\n",
       "================================================================================\n",
       "Total params: 302,397,967\n",
       "Trainable params: 302,397,967\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from the_well.benchmark.models import TFNO\n",
    "from torchinfo import summary\n",
    "\n",
    "# Load The Well model (1.21 GB)\n",
    "well_model = TFNO.from_pretrained(\"polymathic-ai/TFNO-MHD_64\")\n",
    "well_model = well_model.to(\"cuda\")\n",
    "\n",
    "# Have a look at the model summary\n",
    "# Note that the order of layers does not represent order of execution\n",
    "summary(well_model, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3381f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from the_well.data import WellDataset\n",
    "from the_well.data.normalization import ZScoreNormalization\n",
    "\n",
    "# Enable streaming the dataset from HuggingFace\n",
    "# The following line may take a couple of minutes to instantiate the datamodule\n",
    "dataset = WellDataset(\n",
    "    well_base_path=\"hf://datasets/polymathic-ai/\",  # access from HF hub\n",
    "    well_dataset_name=\"MHD_64\",\n",
    "    well_split_name=\"test\",\n",
    "    use_normalization=True,\n",
    "    normalization_type=ZScoreNormalization,\n",
    "    n_steps_input=4,\n",
    "    n_steps_output=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7787d",
   "metadata": {},
   "source": [
    "With the dataset on hand, its features, shape and size can be explored. `The Well` provides a great script for this already, and is left to the reader to go through if desired. A summary is provided below, also available on the [dataset card](https://github.com/PolymathicAI/the_well/blob/master/datasets/MHD_64/README.md) online:\n",
    "\n",
    "**Dimension of discretized data:** 100 timesteps of 64 $\\times$ 64 $\\times$ 64 cubes.\n",
    "\n",
    "**Fields available in the data:** Density (scalar field), velocity (vector field), magnetic field (vector field).\n",
    "\n",
    "**Number of trajectories:** 10 Initial conditions x 10 combination of parameters = 100 trajectories.\n",
    "\n",
    "**Estimated size of the ensemble of all simulations:** 71.6 GB.\n",
    "\n",
    "**Grid type:** uniform grid, cartesian coordinates.\n",
    "\n",
    "**Initial conditions:** uniform IC.\n",
    "\n",
    "**Boundary conditions:** periodic boundary conditions.\n",
    "\n",
    "**Data are stored separated by ($\\Delta t$):** 0.01 (arbitrary units).\n",
    "\n",
    "**Total time range ($t\\_{min}$ to $t\\_{max}$):** $t\\_{min} = 0$, $t\\_{max} = 1$.\n",
    "\n",
    "**Spatial domain size ($L_x$, $L_y$, $L_z$):** dimensionless so 64 pixels.\n",
    "\n",
    "**Set of coefficients or non-dimensional parameters evaluated:** all combinations of $\\mathcal{M}_s=${0.5, 0.7, 1.5, 2.0 7.0} and $\\mathcal{M}_A =${0.7, 2.0}.\n",
    "\n",
    "**Approximate time and hardware used to generate the data:** Downsampled from `MHD_256` after applying ideal low-pass filter.\n",
    "\n",
    "**What phenomena of physical interest are catpured in the data:** MHD fluid flows in the compressible limit (sub and super sonic, sub and super Alfvenic).\n",
    "\n",
    "**How to evaluate a new simulator operating in this space:** Check metrics such as Power spectrum, two-points correlation function.\n",
    "\n",
    "Please cite the associated paper if you use this data in your research:\n",
    "\n",
    "```\n",
    "@article{burkhart2020catalogue,\n",
    "  title={The catalogue for astrophysical turbulence simulations (cats)},\n",
    "  author={Burkhart, B and Appel, SM and Bialy, S and Cho, J and Christensen, AJ and Collins, D and Federrath, Christoph and Fielding, DB and Finkbeiner, D and Hill, AS and others},\n",
    "  journal={The Astrophysical Journal},\n",
    "  volume={905},\n",
    "  number={1},\n",
    "  pages={14},\n",
    "  year={2020},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee44dbf1",
   "metadata": {},
   "source": [
    "A single sample can be extracted and inspected. Some notes from `The Well` are shown below. More info on examining their data can be found in [this example](https://github.com/PolymathicAI/the_well/blob/master/docs/tutorials/dataset.ipynb):\n",
    "\n",
    "The most important elements are `input_fields` and `output_fields`. They represent the time-varying physical fields of the dynamical system and are generally the input and target of our models. For a dynamical system that has 2 spatial dimensions $x$ and $y$, `input_fields` would have a shape $(T_{in}, L_x, L_y, F)$ and `output_fields` would have a shape $(T_{out}, L_x, L_y, F)$. The number of input and output timesteps $T_{in}$ and $T_{out}$ are specified at the instantiation of the dataset with the arguments `n_steps_input` and `n_steps_output`. $L_x$ and $L_y$ are the lengths of the spatial dimensions. $F$ represents the number of physical fields, where vector fields $v = (v_x, v_y)$ and tensor fields $t = (t_{xx}, t_{xy}, t_{yx}, t_{yy})$ are flattened.\n",
    "\n",
    "Note that the dataset for MHD has three spatial dimensions, so an extra $z$ term will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ef513f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: input_fields         Shape: torch.Size([4, 64, 64, 64, 7])\n",
      "Key: output_fields        Shape: torch.Size([1, 64, 64, 64, 7])\n",
      "Key: constant_scalars     Shape: torch.Size([2])\n",
      "Key: boundary_conditions  Shape: torch.Size([3, 2])\n",
      "Key: space_grid           Shape: torch.Size([64, 64, 64, 3])\n",
      "Key: input_time_grid      Shape: torch.Size([4])\n",
      "Key: output_time_grid     Shape: torch.Size([1])\n",
      "Field Names: {0: ['density'], 1: ['magnetic_field_x', 'magnetic_field_y', 'magnetic_field_z', 'velocity_x', 'velocity_y', 'velocity_z'], 2: []}\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "for k, v in sample.items():\n",
    "    print(f\"Key: {k.ljust(20)} Shape: {v.shape}\")\n",
    "\n",
    "print(f\"Field Names: {dataset.metadata.field_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82c7da",
   "metadata": {},
   "source": [
    "Using the model summary from above and the order of operations in the [TFNO forward pass](https://github.com/neuraloperator/neuraloperator/blob/7bb578df787d6ca548b623b83f0601c98dc931fb/neuralop/models/fno.py#L337), the data is processed by:\n",
    "\n",
    "1. Applying optional positional encoding\n",
    "2. Sending inputs through a lifting layer to a high-dimensional latent space\n",
    "3. Applying optional domain padding to high-dimensional intermediate function representation\n",
    "4. Applying `n_layers` Fourier/TFNO layers in sequence (SpectralConvolution + skip connections, nonlinearity) \n",
    "5. If domain padding was applied, domain padding is removed\n",
    "6. Projection of intermediate function representation to the output channels\n",
    "\n",
    "\n",
    "This pretrained model is trained to predict the $T_{out} = 1$ next states given the $T_{in} = 4$ previous states. The input steps are concatenated along their channels, such that the model expects $T_{in} \\times F$ channels as input and $T_{out} \\times F$ channels as output. Because `WellDataset` is a PyTorch dataset, we can use it conveniently with PyTorch data-loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d51d0-246b-4860-8b65-4e26792ba734",
   "metadata": {},
   "source": [
    "We can now evaluate and verify the performacne of the pretrained MHD model from `the_well`. To do this, we will utilize the _streaming_ data mode from `the_well`, and the utilities in the `Trainer` for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f9a80-e804-4da8-ad0a-0109d311b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from the_well.benchmark.metrics import VRMSE\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "well_model.eval()\n",
    "\n",
    "all_batch_mean_normalized_errors = []\n",
    "all_batch_mean_denormalized_errors = []\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "for idx, batch in enumerate(\n",
    "    tqdm(dataloader, total=len(dataloader), desc=\"Evaluating Batches\")\n",
    "):\n",
    "    input_batch = batch[\"input_fields\"].to(\n",
    "        device=\"cuda\"\n",
    "    )  # Shape: (B, Ti, Lx, Ly, Lz, F)\n",
    "    output_batch = batch[\"output_fields\"].to(\n",
    "        device=\"cuda\"\n",
    "    )  # Shape: (B, To, Lx, Ly, Lz, F)\n",
    "\n",
    "    input_batch = rearrange(input_batch, \"B Ti Lx Ly Lz F -> B (Ti F) Lx Ly Lz\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_batch = well_model(input_batch)  # Shape: (B, (To*F), Lx, Ly)\n",
    "\n",
    "        pred_batch = rearrange(\n",
    "            pred_batch, \"B (Tp F) Lx Ly Lz -> B Tp Lx Ly Lz F\", Tp=dataset.n_steps_output\n",
    "        )  # Shape: (B, Tp, Lx, Ly, Lz, F)\n",
    "        normalized_errors_per_sample = VRMSE.eval(\n",
    "            pred_batch, output_batch, dataset.metadata\n",
    "        )\n",
    "        mean_normalized_err = normalized_errors_per_sample.mean().item()\n",
    "        all_batch_mean_normalized_errors.append(mean_normalized_err)\n",
    "\n",
    "        denormalized_pred_batch = dataset.norm.denormalize_flattened(\n",
    "            pred_batch, mode=\"variable\"\n",
    "        )\n",
    "        denormalized_output_batch = dataset.norm.denormalize_flattened(\n",
    "            output_batch, mode=\"variable\"\n",
    "        )\n",
    "        denormalized_errors_per_sample = VRMSE.eval(\n",
    "            denormalized_pred_batch, denormalized_output_batch, dataset.metadata\n",
    "        )\n",
    "        mean_denormalized_err = denormalized_errors_per_sample.mean().item()\n",
    "        all_batch_mean_denormalized_errors.append(mean_denormalized_err)\n",
    "\n",
    "\n",
    "final_mean_normalized = np.mean(all_batch_mean_normalized_errors)\n",
    "final_std_normalized = np.std(all_batch_mean_normalized_errors)\n",
    "final_mean_denormalized = np.mean(all_batch_mean_denormalized_errors)\n",
    "final_std_denormalized = np.std(all_batch_mean_denormalized_errors)\n",
    "\n",
    "print(\"\\n--- Overall Evaluation Results ---\")\n",
    "print(\n",
    "    f\"Total samples evaluated: {len(dataloader)} ({len(dataloader)//dataloader.batch_size} batches of {dataloader.batch_size} samples)\"\n",
    ")\n",
    "print(\n",
    "    f\"Mean Normalized VRMSE: {final_mean_normalized:.6f} (Std Dev: {final_std_normalized:.6f})\"\n",
    ")\n",
    "print(\n",
    "    f\"Mean Denormalized VRMSE: {final_mean_denormalized:.6f} (Std Dev: {final_std_denormalized:.6f})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01dbc4-c509-4102-afb3-741ad2debba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"pred shape: {pred_batch.shape}\")\n",
    "# print(f\"gt shape: {output_batch.shape}\")\n",
    "# normalized_errors_per_sample = VRMSE.eval(pred_batch, output_batch, dataset.metadata)\n",
    "# print(normalized_errors_per_sample.mean().item())\n",
    "# batch['input_fields'].shape\n",
    "# ib = batch['input_fields']\n",
    "# ob = batch['output_fields']\n",
    "# ib.shape\n",
    "# len(dataloader)//dataloader.batch_size\n",
    "# input_batch = rearrange(input_batch, \"B Ti Lx Ly Lz F -> B (Ti F) Lx Ly Lz\")\n",
    "# input_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915ac36-ea41-4821-b38e-1e874cb8da12",
   "metadata": {},
   "source": [
    "## Using The Well Data to Train PhysicsNeMo Models\n",
    "Now that the baseline model from `the_well` has been evaluated, lets look at training a similar architecture from scratch in `PhysicsNeMo`. In the `PhysicsNeMo` examples, there is a similar example of a Tensor-Factorized Fourier Neural Operator implementation that has been used in a related use case for incompressible magnetohydrodynamics in 2D. This model can be adapted for use in 3D with the dataset from `The Well`. This also serves as an example for how `PhysicsNeMo` can be used as a framework for building and testing model architectures that are not found in base model collection. For the remainder of this notebook, a boiler-plate `Trainer` class is implemented in `utils.py` that contains the core components needed for loading models, running training loops, saving checkpoints, evaluating models, etc. The method `setup_model` needs to be implemented in order to use a model from PhysicsNeMo. For completeness, the TFNO architecture from `PhysicsNeMo` is included in the `tfno` folder. Additionally, there is a config file in `config` folder that is used to initialize some parameters for our pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89719e84-8a2e-4056-8b5c-d0c07ed1c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bfd6ad7-efaf-4113-82f8-0f79d4e46b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from training_utils import Trainer\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "initialize(version_base=None, config_path=\"./config\")\n",
    "cfg = compose(config_name=\"mhd_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c09dee18-82aa-474f-8cb8-6d0de3cc5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHDTrainer(Trainer):\n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup the TFNO model based in PhysicsNeMo. Input parameters are set and controlled by the yaml config.\"\"\"\n",
    "        from tfno.tfno import TFNO\n",
    "\n",
    "        self.model = TFNO(\n",
    "            in_channels=self.model_params.in_dim,\n",
    "            coord_features=self.model_params.coord_features,\n",
    "            out_channels=self.model_params.out_dim,\n",
    "            decoder_layers=self.model_params.decoder_layers,\n",
    "            decoder_layer_size=self.model_params.fc_dim,\n",
    "            dimension=self.model_params.dimension,\n",
    "            latent_channels=self.model_params.layers,\n",
    "            num_fno_layers=self.model_params.num_fno_layers,\n",
    "            num_fno_modes=self.model_params.modes,\n",
    "            padding=[\n",
    "                self.model_params.pad_z,\n",
    "                self.model_params.pad_y,\n",
    "                self.model_params.pad_x,\n",
    "            ],\n",
    "            rank=self.model_params.rank,\n",
    "            factorization=self.model_params.factorization,\n",
    "            fixed_rank_modes=self.model_params.fixed_rank_modes,\n",
    "            decomposition_kwargs=self.model_params.decomposition_kwargs,\n",
    "        ).to(self.dist.device)\n",
    "\n",
    "        print(summary(self.model, depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7d158042-3c58-4079-8196-206ba038f9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "TFNO                                          --\n",
      "├─GELU: 1-1                                   --\n",
      "├─FullyConnected: 1-2                         --\n",
      "│    └─ModuleList: 2-1                        --\n",
      "│    │    └─FCLayer: 3-1                      16,512\n",
      "│    └─FCLayer: 2-2                           --\n",
      "│    │    └─Identity: 3-2                     --\n",
      "│    │    └─Linear: 3-3                       903\n",
      "├─TFNO3DEncoder: 1-3                          --\n",
      "│    └─GELU: 2-3                              --\n",
      "│    └─Sequential: 2-4                        --\n",
      "│    │    └─Conv3dFCLayer: 3-4                1,856\n",
      "│    │    └─GELU: 3-5                         --\n",
      "│    │    └─Conv3dFCLayer: 3-6                8,320\n",
      "│    └─ModuleList: 2-5                        --\n",
      "│    │    └─FactorizedSpectralConv3d: 3-7     302,123,348\n",
      "│    └─ModuleList: 2-6                        --\n",
      "│    │    └─Conv3d: 3-8                       16,512\n",
      "======================================================================\n",
      "Total params: 302,167,451\n",
      "Trainable params: 302,167,451\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "mhd_trainer = MHDTrainer(cfg)\n",
    "# mhd_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc37d72-df24-4944-8d3a-37dcc0f65758",
   "metadata": {},
   "source": [
    "## Running Models From The Well in PhysicsNemo\n",
    "\n",
    "PhysicsNeMo offers great utility in running community models natively in PhysicsNeMo by way of a simple conversion. The documentation for this can be found [here](https://docs.nvidia.com/deeplearning/physicsnemo/physicsnemo-core/api/physicsnemo.models.html#converting-pytorch-models-to-physicsnemo-models). The first process of the conversion is setting up the base PyTorch model as a PhysicsNeMo model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1af4d77d-c0d8-402b-bc61-b79f92e9e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'physicsnemo.models.module.Module.from_torch.<locals>.PhysicsNeMoModel'>\n"
     ]
    }
   ],
   "source": [
    "from physicsnemo.registry import ModelRegistry\n",
    "model_registry = ModelRegistry()\n",
    "model_registry.__clear_registry__()\n",
    "model_registry.__restore_registry__()\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from physicsnemo.models.meta import ModelMetaData\n",
    "from physicsnemo.models.module import Module\n",
    "from the_well.benchmark.models import TFNO\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WellMetaData(ModelMetaData):\n",
    "    name: str = \"WellTFNOModel\"\n",
    "\n",
    "\n",
    "well_nemo_model = Module.from_torch(TFNO, meta=WellMetaData())\n",
    "print(well_nemo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54301d85-7faf-4ae0-8345-4991652edd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_hub_mixin_config': {'modes3': 16, 'hidden_channels': 128, 'gradient_checkpointing': False, 'dim_in': 28, 'dim_out': 7, 'n_spatial_dims': 3, 'spatial_resolution': [64, 64, 64], 'modes1': 16, 'modes2': 16}, 'training': True, '_parameters': {}, '_buffers': {}, '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': {'model': NeuralOpsCheckpointWrapper(\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (convs): SpectralConv(\n",
      "      (weight): ModuleList(\n",
      "        (0-3): 4 x ComplexTuckerTensor(shape=(128, 128, 16, 16, 9), rank=(128, 128, 16, 16, 9))\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (lifting): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv3d(28, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (1): Conv3d(256, 7, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")}, 'n_spatial_dims': 3, 'spatial_resolution': [64, 64, 64], 'dim_in': 28, 'dim_out': 7, 'modes1': 16, 'modes2': 16, 'modes3': 16, 'hidden_channels': 128, 'initialized': False, 'gradient_checkpointing': False, 'n_modes': (16, 16, 16)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "TFNOPhysicsNeMoModel                                         --\n",
       "├─TFNO: 1-1                                                  --\n",
       "│    └─NeuralOpsCheckpointWrapper: 2-1                       --\n",
       "│    │    └─FNOBlocks: 3-1                                   --\n",
       "│    │    │    └─SpectralConv: 4-1                           512\n",
       "│    │    │    │    └─ModuleList: 5-1                        302,256,776\n",
       "│    │    │    └─ModuleList: 4-2                             --\n",
       "│    │    │    │    └─Conv3d: 5-2                            16,384\n",
       "│    │    │    │    └─Conv3d: 5-3                            16,384\n",
       "│    │    │    │    └─Conv3d: 5-4                            16,384\n",
       "│    │    │    │    └─Conv3d: 5-5                            16,384\n",
       "│    │    └─MLP: 3-2                                         --\n",
       "│    │    │    └─ModuleList: 4-3                             --\n",
       "│    │    │    │    └─Conv3d: 5-6                            7,424\n",
       "│    │    │    │    └─Conv3d: 5-7                            32,896\n",
       "│    │    └─MLP: 3-3                                         --\n",
       "│    │    │    └─ModuleList: 4-4                             --\n",
       "│    │    │    │    └─Conv3d: 5-8                            33,024\n",
       "│    │    │    │    └─Conv3d: 5-9                            1,799\n",
       "=====================================================================================\n",
       "Total params: 302,397,967\n",
       "Trainable params: 302,397,967\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from physicsnemo.registry import ModelRegistry\n",
    "\n",
    "print(well_model.__dict__)\n",
    "well_nemo_model = ModelRegistry().factory(\"TFNOPhysicsNeMoModel\")(\n",
    "    dim_in=28,\n",
    "    dim_out=7,\n",
    "    n_spatial_dims=3,\n",
    "    spatial_resolution=[64, 64, 64],\n",
    "    hidden_channels=128,\n",
    "    modes1=16,\n",
    "    modes2=16,\n",
    "    modes3=16,\n",
    ")\n",
    "\n",
    "summary(well_nemo_model, depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4248391-ef8f-413e-a29b-5c307cb40e2b",
   "metadata": {},
   "source": [
    "The resulting `well_nemo_model` is simply the underlying PyTorch model from The Well, that can now be used with PhysicsNeMo and its utilities. Note that this is a newly instantiated model. To now train this model in PhysicsNeMo with the same dataset from The Well, we can update our `Trainer` to use this new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a661e334-66e4-4f6c-ae6c-6ddf8fb0fd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set manually from The Well config.\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "TFNOPhysicsNeMoModel                                         --\n",
      "├─TFNO: 1-1                                                  --\n",
      "│    └─NeuralOpsCheckpointWrapper: 2-1                       --\n",
      "│    │    └─FNOBlocks: 3-1                                   --\n",
      "│    │    │    └─SpectralConv: 4-1                           512\n",
      "│    │    │    │    └─ModuleList: 5-1                        302,256,776\n",
      "│    │    │    └─ModuleList: 4-2                             --\n",
      "│    │    │    │    └─Conv3d: 5-2                            16,384\n",
      "│    │    │    │    └─Conv3d: 5-3                            16,384\n",
      "│    │    │    │    └─Conv3d: 5-4                            16,384\n",
      "│    │    │    │    └─Conv3d: 5-5                            16,384\n",
      "│    │    └─MLP: 3-2                                         --\n",
      "│    │    │    └─ModuleList: 4-3                             --\n",
      "│    │    │    │    └─Conv3d: 5-6                            7,424\n",
      "│    │    │    │    └─Conv3d: 5-7                            32,896\n",
      "│    │    └─MLP: 3-3                                         --\n",
      "│    │    │    └─ModuleList: 4-4                             --\n",
      "│    │    │    │    └─Conv3d: 5-8                            33,024\n",
      "│    │    │    │    └─Conv3d: 5-9                            1,799\n",
      "=====================================================================================\n",
      "Total params: 302,397,967\n",
      "Trainable params: 302,397,967\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "class MHDTrainer(Trainer):\n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup the TFNO model based in PhysicsNeMo. Input parameters are set and controlled by the yaml config.\"\"\"\n",
    "        from dataclasses import dataclass\n",
    "        \n",
    "        from physicsnemo.models.meta import ModelMetaData\n",
    "        from physicsnemo.models.module import Module\n",
    "        from the_well.benchmark.models import TFNO\n",
    "        \n",
    "        \n",
    "        @dataclass\n",
    "        class WellMetaData(ModelMetaData):\n",
    "            name: str = \"WellTFNOModel\"\n",
    "        \n",
    "        \n",
    "        well_nemo_model = Module.from_torch(TFNO, meta=WellMetaData())\n",
    "        well_nemo_model = well_nemo_model(\n",
    "            dim_in=28,\n",
    "            dim_out=7,\n",
    "            n_spatial_dims=3,\n",
    "            spatial_resolution=[64, 64, 64],\n",
    "            hidden_channels=128,\n",
    "            modes1=16,\n",
    "            modes2=16,\n",
    "            modes3=16,\n",
    "        )\n",
    "\n",
    "        self.model = well_nemo_model\n",
    "        print(summary(self.model, depth=5))\n",
    "\n",
    "cfg.model_params = \"Set manually from The Well config.\"\n",
    "print(cfg.model_params)\n",
    "        \n",
    "well_model_trainer = MHDTrainer(cfg)\n",
    "# well_model_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72959594-a700-4496-a66d-efbcf06b4a8a",
   "metadata": {},
   "source": [
    "## Fine-tuning Models from The Well in PhysicsNeMo\n",
    "Using the approach of converting models to PhysicsNeMo models allows users to utilize all of the helpful features inside of PhysicsNeMo itself. One great feature of The Well is the abundance of pre-trained model that they provided, often sharing [many pretrained model architectures](https://huggingface.co/collections/polymathic-ai/the-well-benchmark-models-67e69bd7cd8e60229b5cd43e) for a single dataset. These pretrained models can be fine-tuned using PhysicsNeMo by leveraging a similar approach to the above example of converting a model into PhysicsNeMo format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dbaec63e-5347-4c90-a3d1-5d11eae0c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set manually from The Well config.\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "TFNOPhysicsNeMoModel                                         --\n",
      "├─TFNO: 1-1                                                  --\n",
      "│    └─NeuralOpsCheckpointWrapper: 2-1                       --\n",
      "│    │    └─FNOBlocks: 3-1                                   --\n",
      "│    │    │    └─SpectralConv: 4-1                           302,257,288\n",
      "│    │    │    └─ModuleList: 4-2                             65,536\n",
      "│    │    └─MLP: 3-2                                         --\n",
      "│    │    │    └─ModuleList: 4-3                             40,320\n",
      "│    │    └─MLP: 3-3                                         --\n",
      "│    │    │    └─ModuleList: 4-4                             34,823\n",
      "=====================================================================================\n",
      "Total params: 302,397,967\n",
      "Trainable params: 302,397,967\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "class MHDTrainer(Trainer):\n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup the pretrained TFNO model from The Well as a PhysicsNeMo model.\n",
    "        Model input parameters are set from the well, and the original config is updated to reflect this.\"\"\"\n",
    "        import inspect\n",
    "\n",
    "        from physicsnemo.models.meta import ModelMetaData\n",
    "        from physicsnemo.models.module import Module\n",
    "        from the_well.benchmark.models import TFNO\n",
    "\n",
    "        well_model = TFNO.from_pretrained(\"polymathic-ai/TFNO-MHD_64\")\n",
    "        model_dict = well_model.__dict__\n",
    "\n",
    "        signature = inspect.signature(TFNO)\n",
    "        parameters = signature.parameters\n",
    "        filtered_params = {k: model_dict[k] for k in parameters if k in model_dict}\n",
    "\n",
    "        model = Module.from_torch(TFNO, meta=ModelMetaData(name=\"converted_tfno\"))\n",
    "        well_pretrained_model = model(**filtered_params)\n",
    "        well_pretrained_model.inner_model.load_state_dict(\n",
    "            well_model.state_dict(), strict=True\n",
    "        )\n",
    "        self.model = pnm_model.to(self.dist.device)\n",
    "\n",
    "        print(summary(self.model, depth=4))\n",
    "\n",
    "\n",
    "cfg.model_params = \"set manually from The Well config.\"\n",
    "print(f\"Model config (cfg.model_params) are: {cfg.model_params}\")\n",
    "\n",
    "well_model_trainer = MHDTrainer(cfg)\n",
    "# well_model_trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f1bea-cc2c-4cc5-af23-e605dbcadb75",
   "metadata": {},
   "source": [
    "## Expanding The Scope - More Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32b5e8-dfc8-4c1f-878a-d71a7e9304a9",
   "metadata": {},
   "source": [
    "# General Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116e8a9",
   "metadata": {},
   "source": [
    "Essentially we can build a nice example to illustrate the points we make in Converting PyTorch models to PhysicsNeMo models.\n",
    "\n",
    "\n",
    "[Converting PyTorch Models to PhysicsNeMo Models](https://docs.nvidia.com/deeplearning/physicsnemo/physicsnemo-core/api/physicsnemo.models.html)\n",
    "\n",
    "\n",
    "In this example, we show:\n",
    "1. How to bring a pretrained checkpoint from the community (\"The well\") and run it as a PhysicsNeMo user\n",
    "2. Then train the same model architecture in PhysicsNeMo - showcasing how easy it is to work with any community PyTorch model\n",
    "3. Then talk about how someone can experiment with different other architectures - true value of PhysicsNeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be5a5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "export PYTHONPATH=$PYTHONPATH:/workspace/PhysicsNeMo-git/physicsnemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5263aa8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Loading a Pre-trained Model from The Well\n",
    "```python\n",
    "from the_well.benchmark.models import FNO\n",
    "\n",
    "# Load a pre-trained FNO model\n",
    "model = FNO.from_pretrained(\"polymathic-ai/FNO-active_matter\")\n",
    "type(model)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
