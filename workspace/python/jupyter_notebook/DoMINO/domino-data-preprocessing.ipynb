{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics NeMo External Aerodynamics DLI\n",
    "\n",
    "## Notebook 1 - Preprocessing Ahmed body *surface* dataset\n",
    "\n",
    "### Introduction\n",
    "\n",
    "For educational purposes, it's important to use lightweight datasets that are easy to store and manage, especially for users who may not have access to high-performance computing resources. One such dataset is the **Ahmed body surface data**, which includes 3D surface geometry, pressure and wall shear stress data for variations in the Ahmed body geometry and inlet Reynolds number. This dataset is a great choice because it is relatively small in size, yet provides valuable information about aerodynamic simulations. It’s ideal for teaching and experimentation, as it won’t demand excessive storage or computational power. *Note that this dataset was created by the NVIDIA PhysicsNeMo development team and differs from other similar datasets hosted on cloud platforms like AWS.*\n",
    "\n",
    "In this notebook, we will walk through the preprocessing steps required to prepare the **Ahmed body surface dataset** for training with the **DoMINO model**, to predict surface quantities like pressure and wall shear stress. The DoMINO model requires 3D surface geometry in **STL format**. The **STL (Stereolithography)** format is a widely used file format for representing 3D surface geometry in computer-aided design (CAD) applications. It describes the surface of a 3D object using a collection of triangular facets, making it a common format for 3D printing and computational geometry. So, as the first step, we’ll extract the 3D surface geometry from the **VTP files**. These files are commonly used in the **VTK (Visualization Toolkit)** format, which stores surface data as **PolyData**—a structure that represents points, lines, and polygons on the surface.\n",
    "\n",
    "To make the dataset more suitable for machine learning, we will convert the **VTP (VTK PolyData)** format into **NPY (NumPy)** format. This conversion makes the data easier to work with in machine learning workflows, as NumPy arrays are optimized for numerical operations, making computations faster and more efficient. After converting the data into NPY format, it can be stored on disk, where it will be readily accessible for training the model and further analysis.\n",
    "\n",
    "Key aspects of this training:\n",
    "- Understanding the Ahmed body geometry and its aerodynamic characteristics\n",
    "- Processing CFD mesh data for deep learning applications\n",
    "\n",
    "## Table of Contents\n",
    "- [Step 1: Define Experiment Parameters and Dependencies](#step-1-define-experiment-parameters-and-dependencies)\n",
    "  - [Loading Required Libraries](#loading-required-libraries)\n",
    "  - [Dependencies](#dependencies)\n",
    "  - [Experiment Parameters and Variables](#experiment-parameters-and-variables)\n",
    "- [Step 2: Convert VTK to STL Files](#step-2-convert-vtk-to-stl-files)\n",
    "  - [Understanding the Conversion Process](#understanding-the-conversion-process)\n",
    "  - [Key Components and Libraries](#key-components-and-libraries)\n",
    "  - [Important Considerations](#important-considerations)\n",
    "  - [Implementation Overview](#implementation-overview)\n",
    "- [Step 3: Visualizing STL Meshes](#Step-3:-Visualizing-STL-Meshes)\n",
    "- [Step 4: Convert CFD Results to NPY Format](#Step-4:-Convert-CFD-Results-to-NPY-Format)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Define Experiment Parameters and Dependencies**\n",
    "\n",
    "The first step in training the DoMINO model on the Ahmed body surface dataset is to set up our experiment environment and define the necessary parameters. This includes specifying paths to our data, configuring training settings, and ensuring all required libraries are available.\n",
    "\n",
    "Key components we need to set up:\n",
    "- Data paths for training and validation sets\n",
    "- Model hyperparameters and training configurations\n",
    "- Visualization settings for results\n",
    "- Required Python libraries for mesh processing and deep learning\n",
    "\n",
    "### Loading Required Libraries\n",
    "\n",
    "Before we proceed with the experiment setup, let's first import all the necessary libraries. These libraries will be used for:\n",
    "- Mesh processing and visualization (`vtk`, `pyvista`)\n",
    "- Data handling and file operations (`pathlib`, `concurrent.futures`)\n",
    "- Progress tracking and visualization (`tqdm`, `matplotlib`)\n",
    "- PyTorch provides data primitives: `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. `Dataset` stores the samples and their corresponding labels.\n",
    "- Important utilities for data processing and training, testing DoMINO (`modulus.utils.domino.utils`)\n",
    "\n",
    "### Dependencies\n",
    "Ensure that the required Python libraries are installed:\n",
    "\n",
    "```bash\n",
    "apt install -y xvfb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]33m\n",
      "Get:5 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [2066 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [2193 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Packages [45.2 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1458 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [1713 kB]m\u001b[33m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 Packages [48.8 kB]33m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [35.6 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1363 kB]33m\n",
      "Get:13 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [23.0 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1137 kB]\n",
      "Fetched 10.5 MB in 3s (3634 kB/s)33m\u001b[0m\u001b[33m               \u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "85 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libfontenc1 libxfont2 libxkbfile1 libxmuu1 libxrandr2 x11-xkb-utils xauth\n",
      "  xfonts-base xfonts-encodings xfonts-utils xkb-data xserver-common\n",
      "The following NEW packages will be installed:\n",
      "  libfontenc1 libxfont2 libxkbfile1 libxmuu1 libxrandr2 x11-xkb-utils xauth\n",
      "  xfonts-base xfonts-encodings xfonts-utils xkb-data xserver-common xvfb\n",
      "0 upgraded, 13 newly installed, 0 to remove and 85 not upgraded.\n",
      "Need to get 8324 kB of archives.\n",
      "After this operation, 16.2 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 xkb-data all 2.41-2ubuntu1.1 [397 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu noble/main amd64 libxmuu1 amd64 2:1.1.3-3build2 [8958 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu noble/main amd64 xauth amd64 1:1.1.2-1build1 [25.6 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu noble/main amd64 libfontenc1 amd64 1:1.1.8-1build1 [14.0 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu noble/main amd64 libxfont2 amd64 1:2.0.6-1build1 [93.0 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu noble/main amd64 libxkbfile1 amd64 1:1.1.0-1build4 [70.0 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu noble/main amd64 libxrandr2 amd64 2:1.5.2-2build1 [19.7 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu noble/main amd64 x11-xkb-utils amd64 7.7+8build2 [170 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu noble/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu noble/main amd64 xfonts-utils amd64 1:7.7+6build3 [94.4 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu noble/main amd64 xfonts-base all 1:1.0.5+nmu1 [5941 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 xserver-common all 2:21.1.12-1ubuntu1.4 [34.4 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 xvfb amd64 2:21.1.12-1ubuntu1.4 [877 kB]\n",
      "Fetched 8324 kB in 2s (3400 kB/s)m\u001b[33m\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 79, <STDIN> line 13.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package xkb-data.\n",
      "(Reading database ... 26328 files and directories currently installed.)\n",
      "Preparing to unpack .../00-xkb-data_2.41-2ubuntu1.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking xkb-data (2.41-2ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Selecting previously unselected package libxmuu1:amd64.\n",
      "Preparing to unpack .../01-libxmuu1_2%3a1.1.3-3build2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libxmuu1:amd64 (2:1.1.3-3build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package xauth.\n",
      "Preparing to unpack .../02-xauth_1%3a1.1.2-1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking xauth (1:1.1.2-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libfontenc1:amd64.\n",
      "Preparing to unpack .../03-libfontenc1_1%3a1.1.8-1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libfontenc1:amd64 (1:1.1.8-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libxfont2:amd64.\n",
      "Preparing to unpack .../04-libxfont2_1%3a2.0.6-1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libxfont2:amd64 (1:2.0.6-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../05-libxkbfile1_1%3a1.1.0-1build4_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking libxkbfile1:amd64 (1:1.1.0-1build4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libxrandr2:amd64.\n",
      "Preparing to unpack .../06-libxrandr2_2%3a1.5.2-2build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libxrandr2:amd64 (2:1.5.2-2build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package x11-xkb-utils.\n",
      "Preparing to unpack .../07-x11-xkb-utils_7.7+8build2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking x11-xkb-utils (7.7+8build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package xfonts-encodings.\n",
      "Preparing to unpack .../08-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package xfonts-utils.\n",
      "Preparing to unpack .../09-xfonts-utils_1%3a7.7+6build3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking xfonts-utils (1:7.7+6build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package xfonts-base.\n",
      "Preparing to unpack .../10-xfonts-base_1%3a1.0.5+nmu1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking xfonts-base (1:1.0.5+nmu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package xserver-common.\n",
      "Preparing to unpack .../11-xserver-common_2%3a21.1.12-1ubuntu1.4_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking xserver-common (2:21.1.12-1ubuntu1.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package xvfb.\n",
      "Preparing to unpack .../12-xvfb_2%3a21.1.12-1ubuntu1.4_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking xvfb (2:21.1.12-1ubuntu1.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up xkb-data (2.41-2ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libfontenc1:amd64 (1:1.1.8-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libxrandr2:amd64 (2:1.5.2-2build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libxkbfile1:amd64 (1:1.1.0-1build4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libxfont2:amd64 (1:2.0.6-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libxmuu1:amd64 (2:1.1.3-3build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up x11-xkb-utils (7.7+8build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up xfonts-utils (1:7.7+6build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up xfonts-base (1:1.0.5+nmu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up xauth (1:1.1.2-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up xserver-common (2:21.1.12-1ubuntu1.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up xvfb (2:21.1.12-1ubuntu1.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for fontconfig (2.15.0-1.1ubuntu2) ...\n",
      "Processing triggers for libc-bin (2.39-0ubuntu8.4) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install -y xvfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import vtk\n",
    "from stl import mesh\n",
    "from tqdm import tqdm\n",
    "\n",
    "from physicsnemo.utils.domino.utils import *\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Parameters and Variables\n",
    "\n",
    "In this section, we set up all the essential parameters and variables required for the Ahmed body experiment. \n",
    "**Before proceeding, navigate to the data directory and extract the `ahmed_body_dataset.zip` archive. This file contains several sample `.vtp` files needed to run the scripts in this notebook and others.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and Path Configuration\n",
    "DATA_DIR = Path(\"/workspace/GTC/data\")  # Root directory for dataset\n",
    "\n",
    "# Physical Variables\n",
    "VOLUME_VARS = [\"p\"]  # Volume variables to predict (pressure)\n",
    "SURFACE_VARS = [\"p\", \"wallShearStress\"]  # Surface variables to predict\n",
    "AIR_DENSITY = 1.205  # Air density in kg/m³"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Convert VTK to STL Files**\n",
    "\n",
    "The second step in our workflow involves converting the CFD simulation data from VTK format to STL format.\n",
    "\n",
    "#### Understanding the Conversion Process\n",
    "\n",
    "The conversion from VTK to STL involves several key steps:\n",
    "1. Reading the VTK PolyData file using specialized readers\n",
    "2. Extracting the surface geometry and mesh data\n",
    "3. Converting the data while preserving topology and surface properties\n",
    "4. Saving the result in binary STL format\n",
    "\n",
    "#### Key Components and Libraries\n",
    "\n",
    "We'll use the following libraries for this conversion:\n",
    "\n",
    "1. **VTK (Visualization Toolkit)**\n",
    "   - `vtk`: Reads VTK PolyData files (.vtp)\n",
    "   - `vtkSTLWriter`: Writes data in STL format\n",
    "   - `vtkPolyData`: Manages surface mesh data structures\n",
    "\n",
    "2. **File System Operations**\n",
    "   - `os.path`: Handles file paths and directory operations\n",
    "   - `pathlib.Path`: Provides modern path handling capabilities\n",
    "\n",
    "#### Important Considerations\n",
    "\n",
    "During the conversion process, we need to ensure:\n",
    "- Surface normal vectors are preserved correctly\n",
    "- Mesh quality and topology are maintained\n",
    "- The output is compatible with the DoMINO model's requirements\n",
    "- Memory is managed efficiently for large datasets\n",
    "\n",
    "#### Implementation Overview\n",
    "\n",
    "The conversion is implemented through two main functions:\n",
    "\n",
    "1. **Environment Setup**\n",
    "```python\n",
    "def setup_environment(data_dir: str):\n",
    "    \"\"\"Sets up the working directory and returns relevant paths.\"\"\"\n",
    "    # Returns paths for dataset, info files, STL files, and surface data\n",
    "```\n",
    "\n",
    "2. **VTK to STL Conversion**\n",
    "```python\n",
    "def convert_vtk_to_stl(vtk_filename: str, stl_filename: str):\n",
    "    \"\"\"Converts a single .vtp file to .stl format.\"\"\"\n",
    "    # Uses vtkXMLPolyDataReader and vtkSTLWriter for conversion\n",
    "```\n",
    "\n",
    "Let's proceed with implementing these functions and performing the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment(data_dir: str):\n",
    "    \"\"\"Sets up the working directory and returns relevant paths.\"\"\"\n",
    "    print(\"=== Environment Setup ===\")\n",
    "    print(f\"Current data directory: {data_dir}\")\n",
    "\n",
    "    dataset_paths = {split: os.path.join(data_dir, split) for split in [\"train\", \"validation\", \"test\"]}\n",
    "    info_paths = {k: os.path.join(data_dir, f\"{k}_info\") for k in dataset_paths}\n",
    "    stl_paths = {k: os.path.join(data_dir, f\"{k}_stl_files\") for k in dataset_paths}\n",
    "    surface_paths = {k: os.path.join(data_dir, f\"{k}_prepared_surface_data\") for k in dataset_paths}\n",
    "\n",
    "    return dataset_paths, info_paths, stl_paths, surface_paths\n",
    "\n",
    "\n",
    "def convert_vtk_to_stl(vtk_filename: str, stl_filename: str):\n",
    "    \"\"\"Converts a single .vtp file to .stl format.\"\"\"\n",
    "    reader = vtk.vtkXMLPolyDataReader()\n",
    "    reader.SetFileName(vtk_filename)\n",
    "    reader.Update()\n",
    "\n",
    "    if not reader.GetOutput():\n",
    "        print(f\"[ERROR] Failed to read {vtk_filename}\")\n",
    "        return\n",
    "\n",
    "    writer = vtk.vtkSTLWriter()\n",
    "    writer.SetFileName(stl_filename)\n",
    "    writer.SetInputConnection(reader.GetOutputPort())\n",
    "    writer.Write()\n",
    "\n",
    "    del reader, writer  # Free memory\n",
    "\n",
    "\n",
    "def process_file(vtp_file: str, output_path: str):\n",
    "    \"\"\"Processes a single .vtp file and saves it as .stl.\"\"\"\n",
    "    output_file = os.path.join(output_path, os.path.basename(vtp_file).replace(\".vtp\", \".stl\"))\n",
    "    convert_vtk_to_stl(vtp_file, output_file)\n",
    "\n",
    "\n",
    "def convert_vtp_to_stl_batch(dataset_paths: dict, stl_paths: dict):\n",
    "    \"\"\"Processes all .vtp files in dataset_paths and saves them in output_paths.\"\"\"\n",
    "    print(\"\\n=== Starting Conversion Process ===\")\n",
    "\n",
    "    for path in stl_paths.values(): os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    for key, dataset_path in dataset_paths.items():\n",
    "        stl_path = stl_paths[key]\n",
    "        vtp_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith('.vtp')]\n",
    "\n",
    "        if not vtp_files:\n",
    "            print(f\"[WARNING] No .vtp files found in {dataset_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing {len(vtp_files)} files from {dataset_path} → {stl_path}...\")\n",
    "\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            list(tqdm(executor.map(process_file, vtp_files, [stl_path] * len(vtp_files)),\n",
    "                      total=len(vtp_files), desc=f\"Converting {key}\", dynamic_ncols=True))\n",
    "\n",
    "    print(\"=== All Conversions Completed Successfully ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment Setup ===\n",
      "Current data directory: /workspace/GTC/data\n",
      "\n",
      "=== Starting Conversion Process ===\n",
      "\n",
      "Processing 408 files from /workspace/GTC/data/train → /workspace/GTC/data/train_stl_files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train: 100%|██████████| 408/408 [00:04<00:00, 89.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 50 files from /workspace/GTC/data/validation → /workspace/GTC/data/validation_stl_files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting validation: 100%|██████████| 50/50 [00:01<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 50 files from /workspace/GTC/data/test → /workspace/GTC/data/test_stl_files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test: 100%|██████████| 50/50 [00:01<00:00, 32.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Conversions Completed Successfully ===\n"
     ]
    }
   ],
   "source": [
    "dataset_paths, info_paths, stl_paths, surface_paths = setup_environment(DATA_DIR)\n",
    "convert_vtp_to_stl_batch(dataset_paths, stl_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Visualizing STL Meshes**\n",
    "\n",
    "The third step in our workflow focuses on visualizing the converted STL meshes to verify the success of our conversion process. This step is crucial because:\n",
    "\n",
    "#### Understanding the Visualization Process\n",
    "\n",
    "The visualization of STL meshes involves several key aspects:\n",
    "1. Loading the STL files using appropriate visualization libraries\n",
    "2. Setting up the visualization environment with proper parameters\n",
    "3. Rendering the mesh with appropriate colors and properties\n",
    "4. Providing interactive controls for inspection\n",
    "\n",
    "#### Key Components and Libraries\n",
    "\n",
    "We'll use the following libraries for visualization:\n",
    "\n",
    "1. **PyVista**\n",
    "   - `pv.read()`: Loads STL files\n",
    "   - `pv.Plotter()`: Creates interactive visualization windows\n",
    "   - `pv.wrap()`: Converts VTK objects to PyVista meshes\n",
    "\n",
    "2. **Matplotlib**\n",
    "   - For static 2D visualizations if needed\n",
    "   - For saving visualization outputs\n",
    "\n",
    "#### Important Visualization Parameters\n",
    "\n",
    "During the visualization process, we need to consider:\n",
    "- Mesh surface properties (color, opacity)\n",
    "- Camera position and orientation\n",
    "- Lighting conditions\n",
    "- Interactive controls for rotation and zoom\n",
    "- Quality of the rendered output\n",
    "\n",
    "#### Implementation Overview\n",
    "\n",
    "The visualization is implemented through several key functions:\n",
    "\n",
    "1. **Mesh Loading**\n",
    "```python\n",
    "def load_stl_mesh(file_path: str):\n",
    "    \"\"\"Loads an STL file and returns a PyVista mesh object.\"\"\"\n",
    "    # Uses PyVista to read and process the STL file\n",
    "```\n",
    "\n",
    "2. **Interactive Visualization**\n",
    "```python\n",
    "def plot_stl_comparison(mesh1, mesh2, title1=\"Case 3\", title2=\"Case 9\", volume1=None, volume2=None):\n",
    "    \"\"\"Create a multi-view comparison visualization of two STL meshes.\"\"\"\n",
    "    # Sets up the plotter and displays the meshes\n",
    "```\n",
    "\n",
    "Let's proceed with implementing these functions and visualizing our converted meshes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stl(stl_path: str):\n",
    "    \"\"\"Load an STL file and return its PyVista mesh.\"\"\"\n",
    "    stl_file = Path(stl_path)\n",
    "    if not stl_file.exists():\n",
    "        print(f\"[ERROR] STL file not found: {stl_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        mesh = pv.read(str(stl_file))\n",
    "        return mesh\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load STL file: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_stl(stl_path: str):\n",
    "    \"\"\"Load an STL file and return its PyVista mesh.\"\"\"\n",
    "    stl_file = Path(stl_path)\n",
    "    if not stl_file.exists():\n",
    "        print(f\"[ERROR] STL file not found: {stl_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        mesh = pv.read(str(stl_file))\n",
    "        return mesh\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load STL file: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_stl_comparison(mesh1, mesh2, title1=\"Case 3\", title2=\"Case 9\"):\n",
    "    \"\"\"Create a multi-view comparison visualization of two STL meshes.\"\"\"\n",
    "    # Start virtual frame buffer\n",
    "    pv.start_xvfb()\n",
    "\n",
    "    # Create plotter with off-screen rendering\n",
    "    pl = pv.Plotter(shape=(2, 4), window_size=[1600, 800], off_screen=True)\n",
    "\n",
    "\n",
    "    # Display parameters for each case with brighter colors\n",
    "    params_case1 = {\n",
    "        \"show_edges\": True,\n",
    "        \"opacity\": 1.0,\n",
    "        \"edge_color\": 'black',\n",
    "        \"line_width\": 0.5,\n",
    "        \"color\": [0.6, 0.8, 1.0],\n",
    "        \"smooth_shading\": True,\n",
    "        \"specular\": 0.4,\n",
    "        \"specular_power\": 10,\n",
    "        \"diffuse\": 0.9,\n",
    "        \"ambient\": 1.0,\n",
    "    }\n",
    "\n",
    "    params_case2 = {\n",
    "        \"show_edges\": True,\n",
    "        \"opacity\": 1.0,\n",
    "        \"edge_color\": 'black',\n",
    "        \"line_width\": 0.5,\n",
    "        \"color\": [0.7, 1.0, 0.7],\n",
    "        \"smooth_shading\": True,\n",
    "        \"specular\": 0.4,\n",
    "        \"specular_power\": 10,\n",
    "        \"diffuse\": 0.9,\n",
    "        \"ambient\": 1.0,\n",
    "    }\n",
    "\n",
    "    def setup_view(pl, mesh, title, view_type, params):\n",
    "        \"\"\"Helper function to set up consistent views\"\"\"\n",
    "        pl.add_mesh(mesh, **params)\n",
    "        pl.add_text(title, position=\"upper_edge\", font_size=10, color='black')\n",
    "        pl.add_axes(line_width=2)\n",
    "\n",
    "        if view_type == \"xy\":\n",
    "            pl.view_xy()\n",
    "        elif view_type == \"xz\":\n",
    "            pl.view_xz()\n",
    "        elif view_type == \"yz\":\n",
    "            pl.view_yz()\n",
    "        else:  # isometric\n",
    "            pl.view_isometric()\n",
    "\n",
    "        pl.reset_camera()\n",
    "        pl.camera.zoom(0.85)\n",
    "        # Add directional lighting\n",
    "\n",
    "    # Plot views for both meshes\n",
    "    views = [(\"xy\", \"Top\"), (\"xz\", \"Front\"), (\"yz\", \"Side\"), (\"isometric\", \"Isometric\")]\n",
    "\n",
    "    # First mesh (top row)\n",
    "    for col, (view_type, view_name) in enumerate(views):\n",
    "        pl.subplot(0, col)\n",
    "        setup_view(pl, mesh1, f\"{title1} - {view_name}\", view_type, params_case1)\n",
    "\n",
    "    # Second mesh (bottom row)\n",
    "    for col, (view_type, view_name) in enumerate(views):\n",
    "        pl.subplot(1, col)\n",
    "        setup_view(pl, mesh2, f\"{title2} - {view_name}\", view_type, params_case2)\n",
    "\n",
    "    pl.background_color = '#f0f0f0'\n",
    "\n",
    "    # Display in notebook\n",
    "    return pl.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot two geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STL File Comparison ===\n",
      "\n",
      "File: case102.stl vs case116.stl\n",
      "Number of Faces: 153241 vs 115391\n",
      "Surface Area: 0.93 vs 0.68\n",
      "Volume: 0.070 vs 0.049 m³\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pyvista/core/pointset.py:1365: PyVistaDeprecationWarning: The current behavior of `pv.PolyData.n_faces` has been deprecated.\n",
      "                Use `pv.PolyData.n_cells` or `pv.PolyData.n_faces_strict` instead.\n",
      "                See the documentation in '`pv.PolyData.n_faces` for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Please install Xvfb with:\n\nDebian\n$ sudo apt install libgl1-mesa-glx xvfb\n\nCentOS / RHL\n$ sudo yum install libgl1-mesa-glx xvfb\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolume: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmesh1\u001b[38;5;241m.\u001b[39mvolume\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmesh2\u001b[38;5;241m.\u001b[39mvolume\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m m³\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create visualization with volumes included\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mplot_stl_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCase 102\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCase 116\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mplot_stl_comparison\u001b[0;34m(mesh1, mesh2, title1, title2)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a multi-view comparison visualization of two STL meshes.\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Start virtual frame buffer\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mpv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_xvfb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create plotter with off-screen rendering\u001b[39;00m\n\u001b[1;32m     35\u001b[0m pl \u001b[38;5;241m=\u001b[39m pv\u001b[38;5;241m.\u001b[39mPlotter(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m), window_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1600\u001b[39m, \u001b[38;5;241m800\u001b[39m], off_screen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyvista/plotting/utilities/xvfb.py:50\u001b[0m, in \u001b[0;36mstart_xvfb\u001b[0;34m(wait, window_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`start_xvfb` is only supported on Linux\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhich Xvfb > /dev/null\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(XVFB_INSTALL_NOTES)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# use current default window size\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m window_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: Please install Xvfb with:\n\nDebian\n$ sudo apt install libgl1-mesa-glx xvfb\n\nCentOS / RHL\n$ sudo yum install libgl1-mesa-glx xvfb\n\n"
     ]
    }
   ],
   "source": [
    "# Define STL file paths\n",
    "STL_FILE_1 = DATA_DIR / \"train_stl_files/case102.stl\"\n",
    "STL_FILE_2 = DATA_DIR / \"train_stl_files/case116.stl\"\n",
    "\n",
    "# Load STL files\n",
    "mesh1 = load_stl(STL_FILE_1)\n",
    "mesh2 = load_stl(STL_FILE_2)\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n=== STL File Comparison ===\\n\")\n",
    "print(f\"File: {STL_FILE_1.name} vs {STL_FILE_2.name}\")\n",
    "print(f\"Number of Faces: {mesh1.n_faces} vs {mesh2.n_faces}\")\n",
    "print(f\"Surface Area: {mesh1.area:.2f} vs {mesh2.area:.2f}\")\n",
    "print(f\"Volume: {mesh1.volume:.3f} vs {mesh2.volume:.3f} m³\")\n",
    "\n",
    "# Create visualization with volumes included\n",
    "plot_stl_comparison(mesh1, mesh2, title1=\"Case 102\", title2=\"Case 116\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Convert CFD Results to NPY Format**\n",
    "\n",
    "The fourth step in our workflow focuses on converting CFD simulation results into NumPy (.npy) format for efficient training. As previously mentioned, the advantages of using the NPY format include:\n",
    "- NPY format provides faster data loading during training\n",
    "- Enables efficient memory management for large datasets\n",
    "- Facilitates parallel processing of simulation data\n",
    "- Optimizes data access patterns for deep learning frameworks\n",
    "\n",
    "#### Understanding the Conversion Process\n",
    "\n",
    "The conversion process involves several key aspects:\n",
    "1. Reading CFD simulation data from VTK files\n",
    "2. Extracting surface and volume variables\n",
    "3. Processing mesh geometry and physical quantities\n",
    "4. Normalizing data using appropriate scaling factors\n",
    "5. Saving processed data in NPY format\n",
    "\n",
    "#### Key Components and Libraries\n",
    "\n",
    "We'll use the following libraries for the conversion:\n",
    "\n",
    "1. **VTK and PyVista**\n",
    "   - For reading CFD simulation data\n",
    "   - For processing mesh geometry and surface properties\n",
    "   - For computing cell sizes and normals\n",
    "\n",
    "2. **NumPy**\n",
    "   - For efficient array operations\n",
    "   - For saving data in NPY format\n",
    "\n",
    "3. **Concurrent Processing**\n",
    "   - For parallel processing of multiple files\n",
    "   - For improved conversion speed\n",
    "\n",
    "#### Important Data Processing Parameters\n",
    "\n",
    "During the conversion process, we need to consider:\n",
    "- Surface variables (pressure, wall shear stress)\n",
    "- Mean variables (mean wall shear stress, mean pressure)\n",
    "- Data normalization using inlet velocity and density. **The inlet velocity will be read from the info files**\n",
    "  ```python\n",
    "          with open(info_path, \"r\") as file:\n",
    "            velocity = next(float(line.split(\":\")[1].strip()) for line in file if \"Velocity\" in line)\n",
    "  ```\n",
    "- Mesh geometry preservation\n",
    "- Memory efficiency for large datasets\n",
    "\n",
    "#### Implementation Overview\n",
    "\n",
    "The conversion is implemented through several key components:\n",
    "\n",
    "1. **Dataset Class**\n",
    "```python\n",
    "class OpenFoamAhmedBodySurfaceDataset(Dataset):\n",
    "    \"\"\"Datapipe for converting OpenFOAM dataset to npy.\"\"\"\n",
    "    # Handles data loading and processing\n",
    "```\n",
    "\n",
    "2. **File Processing Functions**\n",
    "```python\n",
    "def process_file(fname: str, fm_data, output_path: str):\n",
    "    \"\"\"Processes a single surface data file.\"\"\"\n",
    "    # Converts individual files to NPY format\n",
    "```\n",
    "\n",
    "3. **Batch Processing**\n",
    "```python\n",
    "def process_surface_data_batch(dataset_paths, info_paths, stl_paths, surface_paths):\n",
    "    \"\"\"Processes all surface data files in parallel.\"\"\"\n",
    "    # Handles parallel processing of multiple files\n",
    "```\n",
    "\n",
    "Let's proceed with implementing these components and converting our CFD results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenFoamAhmedBodySurfaceDataset(Dataset):\n",
    "    \"\"\"Datapipe for converting OpenFOAM dataset to npy.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: Union[str, Path], info_path: Union[str, Path], stl_path: Union[str, Path], surface_variables=None, volume_variables=None, device: int = 0):\n",
    "        self.data_path = Path(data_path).expanduser()\n",
    "        self.stl_path = Path(stl_path).expanduser()\n",
    "        self.info_path = Path(info_path).expanduser()\n",
    "        assert self.data_path.exists(), f\"Path {self.data_path} does not exist\"\n",
    "\n",
    "        self.filenames = get_filenames(self.data_path)\n",
    "        random.shuffle(self.filenames)\n",
    "        self.surface_variables = surface_variables or [\"p\", \"wallShearStress\"]\n",
    "        self.volume_variables = volume_variables or [\"UMean\", \"pMean\"]\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cfd_filename = self.filenames[idx]\n",
    "        car_dir = self.data_path / cfd_filename\n",
    "\n",
    "        stl_path = self.stl_path / f\"{car_dir.stem}.stl\"\n",
    "        info_path = self.info_path / f\"{car_dir.stem}_info.txt\"\n",
    "\n",
    "        with open(info_path, \"r\") as file:\n",
    "            velocity = next(float(line.split(\":\")[1].strip()) for line in file if \"Velocity\" in line)\n",
    "\n",
    "        mesh_stl = pv.get_reader(stl_path).read()\n",
    "        stl_faces = mesh_stl.faces.reshape(-1, 4)[:, 1:]\n",
    "        stl_sizes = np.array(mesh_stl.compute_cell_sizes(length=False, area=True, volume=False).cell_data[\"Area\"])\n",
    "\n",
    "        reader = vtk.vtkXMLPolyDataReader()\n",
    "        reader.SetFileName(str(car_dir))\n",
    "        reader.Update()\n",
    "        polydata = reader.GetOutput()\n",
    "\n",
    "        celldata = get_node_to_elem(polydata).GetCellData()\n",
    "        surface_fields = np.concatenate(get_fields(celldata, self.surface_variables), axis=-1) / (AIR_DENSITY * velocity**2)\n",
    "\n",
    "        mesh = pv.PolyData(polydata)\n",
    "        surface_sizes = np.array(mesh.compute_cell_sizes(length=False, area=True, volume=False).cell_data[\"Area\"])\n",
    "        surface_normals = mesh.cell_normals / np.linalg.norm(mesh.cell_normals, axis=1)[:, np.newaxis]\n",
    "\n",
    "        return {\n",
    "            \"stl_coordinates\": mesh_stl.points.astype(np.float32),\n",
    "            \"stl_centers\": mesh_stl.cell_centers().points.astype(np.float32),\n",
    "            \"stl_faces\": stl_faces.flatten().astype(np.float32),\n",
    "            \"stl_areas\": stl_sizes.astype(np.float32),\n",
    "            \"surface_mesh_centers\": mesh.cell_centers().points.astype(np.float32),\n",
    "            \"surface_normals\": surface_normals.astype(np.float32),\n",
    "            \"surface_areas\": surface_sizes.astype(np.float32),\n",
    "            \"volume_fields\": None,\n",
    "            \"volume_mesh_centers\": None,\n",
    "            \"surface_fields\": surface_fields.astype(np.float32),\n",
    "            \"filename\": cfd_filename,\n",
    "            \"stream_velocity\": velocity,\n",
    "            \"air_density\": AIR_DENSITY,\n",
    "        }\n",
    "\n",
    "def process_file(fname: str, fm_data, output_path: str):\n",
    "    \"\"\"Processes a single surface data file.\"\"\"\n",
    "    full_path, output_file = os.path.join(fm_data.data_path, fname), os.path.join(output_path, f\"{fname}.npy\")\n",
    "    if os.path.exists(output_file) or not os.path.exists(full_path) or os.path.getsize(full_path) == 0:\n",
    "        return\n",
    "    np.save(output_file, fm_data[fm_data.filenames.index(fname)])\n",
    "\n",
    "def process_surface_data_batch(dataset_paths: dict, info_paths: dict, stl_paths: dict, surface_paths: dict):\n",
    "    \"\"\"Processes all surface data files in dataset_paths and saves them in output_paths.\"\"\"\n",
    "\n",
    "    for path in surface_paths.values(): os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    print(\"=== Starting Processing ===\")\n",
    "    for key, dataset_path in dataset_paths.items():\n",
    "        surface_path = surface_paths[key]\n",
    "        os.makedirs(surface_path, exist_ok=True)\n",
    "        fm_data = OpenFoamAhmedBodySurfaceDataset(dataset_path, info_paths[key], stl_paths[key], VOLUME_VARS, SURFACE_VARS)\n",
    "        file_list = [fname for fname in fm_data.filenames if fname.endswith(\".vtp\")]\n",
    "\n",
    "        print(f\"\\nProcessing {len(file_list)} files from {dataset_path} → {surface_path}...\")\n",
    "\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            list(tqdm(executor.map(process_file, file_list, [fm_data]*len(file_list), [surface_path]*len(file_list)),\n",
    "                      total=len(file_list), desc=f\"Processing {key}\", dynamic_ncols=True))\n",
    "\n",
    "    print(\"=== All Processing Completed Successfully ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Processing ===\n",
      "\n",
      "Processing 408 files from /workspace/GTC/data/train → /workspace/GTC/data/train_prepared_surface_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 408/408 [00:02<00:00, 154.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 50 files from /workspace/GTC/data/validation → /workspace/GTC/data/validation_prepared_surface_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation: 100%|██████████| 50/50 [00:00<00:00, 67.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 50 files from /workspace/GTC/data/test → /workspace/GTC/data/test_prepared_surface_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 100%|██████████| 50/50 [00:00<00:00, 60.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Processing Completed Successfully ===\n"
     ]
    }
   ],
   "source": [
    "process_surface_data_batch(dataset_paths, info_paths, stl_paths, surface_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
