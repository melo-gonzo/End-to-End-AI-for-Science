{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics NeMo External Aerodynamics DLI\n",
    "\n",
    "## Notebook 1 - Preprocessing Ahmed body *surface* dataset\n",
    "\n",
    "### Introduction\n",
    "\n",
    "For educational purposes, it's important to use lightweight datasets that are easy to store and manage, especially for users who may not have access to high-performance computing resources. One such dataset is the **Ahmed body surface data**, which includes 3D surface geometry, pressure and wall shear stress data for variations in the Ahmed body geometry and inlet Reynolds number. This dataset is a great choice because it is relatively small in size, yet provides valuable information about aerodynamic simulations. It’s ideal for teaching and experimentation, as it won’t demand excessive storage or computational power. *Note that this dataset was created by the NVIDIA PhysicsNeMo development team and differs from other similar datasets hosted on cloud platforms like AWS.* As mentioned already the complete Ahmed body surface dataset is hosted on NGC and accessible from the following link:\n",
    "https://catalog.ngc.nvidia.com/orgs/nvidia/teams/physicsnemo/resources/physicsnemo_ahmed_body_dataset\n",
    "\n",
    "**Before proceeding, navigate to the data directory and make sure that the Ahmed body dataset is downloaded properly. The folder structure should be:**\n",
    "```bash\n",
    "physicsnemo_ahmed_body_dataset_vv1/dataset\n",
    "├── train/\n",
    "├── train_info/\n",
    "├── train_stl_files/\n",
    "├── validation/\n",
    "├── validation_info/\n",
    "├── validation_stl_files/\n",
    "├── test/\n",
    "├── test_info/\n",
    "├── test_stl_files/\n",
    "```\n",
    "\n",
    "\n",
    "In this notebook, we will walk through the preprocessing steps required to prepare the **Ahmed body surface dataset** for training with the **DoMINO model**, which predicts surface quantities such as pressure and wall shear stress.  \n",
    "\n",
    "For **surface traning** the DoMINO model requires **3D surface geometry** in both **STL** and **VTP (VTK PolyData)** formats:  \n",
    "\n",
    "- **STL (Stereolithography)**  \n",
    "  - A widely used file format for representing 3D surface geometry in computer-aided design (CAD) applications.  \n",
    "  - Describes the surface as a collection of triangular facets, suitable for computational geometry, 3D printing, and mesh-based simulations.  \n",
    "\n",
    "- **VTP (VTK PolyData)**  \n",
    "  - A format from the **VTK (Visualization Toolkit)** that stores surface data as **PolyData**, representing points, lines, and polygons on the surface.  \n",
    "  - Commonly used in CFD and physics-informed simulations.  \n",
    "\n",
    "Both data formats are required for DoMINO surface training:  \n",
    "\n",
    "- **STL files** provide the 3D geometry informattion.  \n",
    "- **VTP files** store additional surface quantities such as pressure and wall shear stress.  \n",
    "\n",
    "To make the dataset easier to use in machine learning workflows and feeding into the GPU, the **data is converted into NumPy arrays (NPY format)**:  \n",
    "\n",
    "- Allows efficient numerical operations and faster computations.  \n",
    "- Facilitates convenient storage on disk, making the data readily accessible for training and further analysis.\n",
    "\n",
    "## Table of Contents\n",
    "- [Step 1: Define Experiment Parameters and Dependencies](#step-1-define-experiment-parameters-and-dependencies)\n",
    "  - [Loading Required Libraries](#loading-required-libraries)\n",
    "  - [Dependencies](#dependencies)\n",
    "  - [Experiment Parameters and Variables](#experiment-parameters-and-variables)\n",
    "- [Step 2: Conversion Pipeline: VTP + STL + Global Parameters → NumPy](#step-2-conversion-pipeline-vtp--stl--global-parameters-→-numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Define Experiment Parameters and Dependencies**\n",
    "\n",
    "The first step in training the DoMINO model on the Ahmed body surface dataset is to set up our experiment environment and define the necessary parameters. This includes specifying paths to our data, configuring training settings, and ensuring all required libraries are available.\n",
    "\n",
    "Key components we need to set up:\n",
    "- Data paths for training and validation sets\n",
    "- Model hyperparameters and training configurations\n",
    "- Visualization settings for results\n",
    "- Required Python libraries for mesh processing and deep learning\n",
    "\n",
    "### Loading Required Libraries\n",
    "\n",
    "Before we proceed with the experiment setup, let's first import all the necessary libraries. These libraries will be used for:\n",
    "- Mesh processing and visualization (`vtk`, `pyvista`)\n",
    "- Data handling and file operations (`pathlib`, `concurrent.futures`)\n",
    "- Progress tracking and visualization (`tqdm`, `matplotlib`)\n",
    "- PyTorch provides data primitives: `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. `Dataset` stores the samples and their corresponding labels.\n",
    "- Important utilities for data processing and training, testing DoMINO (`modulus.utils.domino.utils`)\n",
    "\n",
    "### Dependencies\n",
    "Ensure that the required Python libraries are installed:\n",
    "\n",
    "```bash\n",
    "pip install numpy pyvista vtk matplotlib tqdm numpy-stl\n",
    "apt update\n",
    "apt install -y xvfb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/physicsnemo/utils/filesystem.py:76: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  pattern = re.compile(f\"{suffix}[\\w-]+(/[\\w-]+)?/[\\w-]+@[A-Za-z0-9.]+/[\\w/](.*)\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import vtk\n",
    "from stl import mesh\n",
    "from tqdm import tqdm\n",
    "\n",
    "from physicsnemo.utils.domino.utils import *\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Parameters and Variables\n",
    "\n",
    "In this section, we set up all the essential parameters and variables required for the Ahmed body experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and Path Configuration\n",
    "DATA_DIR = Path(\"/workspace/physicsnemo_ahmed_body_dataset_vv1/dataset\")  # Root directory for dataset\n",
    "\n",
    "# Physical Variables\n",
    "VOLUME_VARS = [\"p\"]  # Volume variables to predict (pressure)\n",
    "SURFACE_VARS = [\"p\", \"wallShearStress\"]  # Surface variables to predict\n",
    "GLOBAL_PARAMS_TYPES = {\"inlet_velocity\": \"vector\", \"air_density\": \"scalar\"}\n",
    "GLOBAL_PARAMS_REFERENCE = {\"inlet_velocity\": [50.0], \"air_density\": 1.226}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The function `setup_environment` prepares the environment for processing the Ahmed Body dataset.\n",
    "\n",
    "* It generates structured paths for each split: **train**, **validation**, **test**.\n",
    "\n",
    "* Each split has:\n",
    "\n",
    "    * Raw **VTP files** for surface simulation data.\n",
    "    \n",
    "    * **Info files** for global parameters like inlet velocity.\n",
    "    \n",
    "    * **STL files** for 3D geometry.\n",
    "    \n",
    "    * Output folder for **processed NumPy surface data**.\n",
    "\n",
    "* Printing the paths ensures the user can quickly verify that all directories are correctly set up.\n",
    "\n",
    "You can now call it like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment(data_dir: str):\n",
    "    \"\"\"\n",
    "    Sets up the working environment by defining the folder paths for training, validation, and test splits.\n",
    "    \n",
    "    This function helps organize the dataset for preprocessing and downstream training.\n",
    "    \n",
    "    Returns:\n",
    "        dataset_paths: Dict with paths to VTP/STL files for each split.\n",
    "        info_paths: Dict with paths to global parameter info files.\n",
    "        stl_paths: Dict with paths to STL geometry files.\n",
    "        surface_paths: Dict with paths to save processed NumPy surface data.\n",
    "    \"\"\"\n",
    "    print(\"=== Environment Setup ===\")\n",
    "    print(f\"Current data directory: {data_dir}\")\n",
    "\n",
    "    # Paths to raw VTP/mesh data\n",
    "    dataset_paths = {split: os.path.join(data_dir, split) for split in [\"train\", \"validation\", \"test\"]}\n",
    "    \n",
    "    # Paths to global parameter info files (text files)\n",
    "    info_paths = {k: os.path.join(data_dir, f\"{k}_info\") for k in dataset_paths}\n",
    "    \n",
    "    # Paths to STL files\n",
    "    stl_paths = {k: os.path.join(data_dir, f\"{k}_stl_files\") for k in dataset_paths}\n",
    "    \n",
    "    # Paths to save processed surface data as NumPy arrays\n",
    "    surface_paths = {k: os.path.join(data_dir, f\"{k}_prepared_surface_data\") for k in dataset_paths}\n",
    "\n",
    "    # Print all paths for confirmation\n",
    "    print(\"\\nConfigured directory paths:\")\n",
    "    for split in dataset_paths:\n",
    "        print(f\"  {split.capitalize()} data: {dataset_paths[split]}\")\n",
    "        print(f\"  {split.capitalize()} info: {info_paths[split]}\")\n",
    "        print(f\"  {split.capitalize()} STL: {stl_paths[split]}\")\n",
    "        print(f\"  {split.capitalize()} prepared surface data: {surface_paths[split]}\\n\")\n",
    "\n",
    "    return dataset_paths, info_paths, stl_paths, surface_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets load the environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment Setup ===\n",
      "Current data directory: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset\n",
      "\n",
      "Configured directory paths:\n",
      "  Train data: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/train\n",
      "  Train info: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/train_info\n",
      "  Train STL: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/train_stl_files\n",
      "  Train prepared surface data: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/train_prepared_surface_data\n",
      "\n",
      "  Validation data: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/validation\n",
      "  Validation info: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/validation_info\n",
      "  Validation STL: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/validation_stl_files\n",
      "  Validation prepared surface data: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/validation_prepared_surface_data\n",
      "\n",
      "  Test data: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/test\n",
      "  Test info: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/test_info\n",
      "  Test STL: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/test_stl_files\n",
      "  Test prepared surface data: /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/test_prepared_surface_data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_paths, info_paths, stl_paths, surface_paths = setup_environment(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Conversion Pipeline: VTP + STL + Global Parameters → NumPy\n",
    "\n",
    "This code block defines a pipeline to convert 3D surface CFD data of the Ahmed body into a **NumPy-based format** suitable for training with the **DoMINO model**. The pipeline combines:\n",
    "\n",
    "- **VTP (VTK PolyData)**: surface simulation results (pressure, wall shear stress)\n",
    "- **STL**: 3D surface geometry\n",
    "- **Global parameters**: inlet velocity (from the info files)\n",
    "\n",
    "### Pipeline Steps\n",
    "\n",
    "- **Dataset Initialization (`OpenFoamAhmedBodySurfaceDataset`)**\n",
    "  - Takes paths for VTP data, STL files, and info files.\n",
    "  - Reads all filenames in the dataset folder and shuffles them.\n",
    "  - Specifies which surface and volume variables to extract.\n",
    "  \n",
    "- **Load Data (`__getitem__`)**\n",
    "  - For a given index:\n",
    "    - Reads the CFD VTP file using `vtkXMLPolyDataReader`.\n",
    "    - Reads the corresponding STL file using `pyvista` to get geometry:\n",
    "      - Node coordinates (`points`)\n",
    "      - Cell centers\n",
    "      - Face connectivity\n",
    "      - Cell areas\n",
    "    - Reads the inlet velocity from the info file. The inlet velocity is read from the info text file corresponding to each case and stored in the NumPy dictionary as \"stream_velocity\" for normalization of surface fields.\n",
    "      ```python\n",
    "         with open(info_path, \"r\") as file:\n",
    "         velocity = next(float(line.split(\":\")[1].strip()) for line in file if \"Velocity\" in line)\n",
    "         # later added to returned dictionary\n",
    "         \"stream_velocity\": velocity,\n",
    "      ```\n",
    "    - Extracts and normalizes surface fields (e.g., pressure, wall shear stress).\n",
    "    - Computes surface normals and area for each mesh cell.\n",
    "    - Returns a dictionary containing:\n",
    "      ```python\n",
    "      {\n",
    "        \"stl_coordinates\": ...,\n",
    "        \"stl_centers\": ...,\n",
    "        \"stl_faces\": ...,\n",
    "        \"stl_areas\": ...,\n",
    "        \"surface_mesh_centers\": ...,\n",
    "        \"surface_normals\": ...,\n",
    "        \"surface_areas\": ...,\n",
    "        \"volume_fields\": None,\n",
    "        \"volume_mesh_centers\": None,\n",
    "        \"surface_fields\": ...,\n",
    "        \"filename\": ...,\n",
    "        \"stream_velocity\": ...,\n",
    "        \"air_density\": ...\n",
    "      }\n",
    "      ```\n",
    "\n",
    "- **File Processing (`process_file`)**\n",
    "  - Saves each sample as a `.npy` file for efficient storage and fast loading.\n",
    "  - Skips files if they already exist or are empty.\n",
    "\n",
    "- **Batch Processing (`process_surface_data_batch`)**\n",
    "  - Iterates over all datasets and corresponding STL/info paths.\n",
    "  - Creates output directories for the converted `.npy` files.\n",
    "  - Uses a **ProcessPoolExecutor** for parallel processing of all files.\n",
    "  - Progress is tracked with `tqdm`.\n",
    "\n",
    "### Summary\n",
    "- **VTP Files**: Contain CFD surface simulation results (pressure, wall shear stress, etc.).\n",
    "- **STL Files**: Provide the 3D surface geometry of the mesh.\n",
    "- **Info Files**: Contain global parameters such as inlet velocity.\n",
    "- **OpenFoamAhmedBodySurfaceDataset**: Combines VTP, STL, and info data into a structured format.\n",
    "- **Extracted Data Dictionary**: Includes mesh points, normals, areas, surface fields, and global parameters.\n",
    "- **.npy Files**: Store the processed data efficiently for fast loading in machine learning workflows.\n",
    "- **DoMINO Training**: The final stage where the processed NumPy dataset is used for training DoMINO model. \n",
    "\n",
    "This diagram will help readers visualize the end-to-end data conversion pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    %% Input Section\n",
    "    subgraph INPUT_DATA [\"Input Data\"]\n",
    "        A[VTP Files - PolyData]\n",
    "        B[STL Files - 3D Geometry]\n",
    "        D[Info Files - e.g. Inlet Velocity]\n",
    "    end\n",
    "\n",
    "    %% Processing Node\n",
    "    C[OpenFOAM Ahmed Body Surface Dataset]\n",
    "\n",
    "    %% Output Section\n",
    "    E[Extracted Data Dictionary]\n",
    "    F[Saved as .npy Files]\n",
    "    G[Ready for DoMINO Training]\n",
    "\n",
    "    %% Data Flow\n",
    "    A --> C\n",
    "    B --> C\n",
    "    D --> C\n",
    "    C --> E\n",
    "    E --> F\n",
    "    F --> G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenFoamAhmedBodySurfaceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Datapipe for converting OpenFOAM Ahmed Body surface dataset into NumPy arrays.\n",
    "\n",
    "    This class reads the VTP surface simulation files, STL geometry files, and info\n",
    "    files containing global parameters (like inlet velocity) to prepare data for\n",
    "    machine learning workflows.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: Union[str, Path], info_path: Union[str, Path], stl_path: Union[str, Path], surface_variables=None, volume_variables=None, global_params_types=None, global_params_reference=None, device: int = 0):\n",
    "        \"\"\"\n",
    "        Initializes the dataset object.\n",
    "\n",
    "        Args:\n",
    "            data_path: Path to VTP files (surface CFD results).\n",
    "            info_path: Path to global parameter files (text files).\n",
    "            stl_path: Path to STL geometry files.\n",
    "            surface_variables: List of surface fields to extract (default: [\"p\", \"wallShearStress\"]).\n",
    "            volume_variables: List of volume fields (default: [\"UMean\", \"pMean\"]).\n",
    "            device: Device ID for loading to GPU (optional).\n",
    "        \"\"\"\n",
    "        self.data_path = Path(data_path).expanduser()\n",
    "        self.stl_path = Path(stl_path).expanduser()\n",
    "        self.info_path = Path(info_path).expanduser()\n",
    "        assert self.data_path.exists(), f\"Path {self.data_path} does not exist\"\n",
    "\n",
    "        # List all VTP files and shuffle for random sampling\n",
    "        self.filenames = get_filenames(self.data_path)\n",
    "        random.shuffle(self.filenames)\n",
    "        self.surface_variables = surface_variables or [\"p\", \"wallShearStress\"]\n",
    "        self.volume_variables = volume_variables or [\"UMean\", \"pMean\"]\n",
    "        self.global_params_types = global_params_types\n",
    "        self.global_params_reference = global_params_reference\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of files in the dataset.\"\"\"\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Reads one file and converts it to a dictionary of NumPy arrays.\n",
    "\n",
    "        Steps:\n",
    "        1. Read global parameter info (inlet velocity) from info file.\n",
    "        2. Read STL file to get mesh points, faces, and surface areas.\n",
    "        3. Read VTP file to get surface CFD fields (pressure, shear stress).\n",
    "        4. Normalize surface fields using velocity and air density.\n",
    "        5. Compute surface normals and areas.\n",
    "        6. Return a dictionary containing all relevant NumPy arrays.\n",
    "        \"\"\"\n",
    "        cfd_filename = self.filenames[idx]\n",
    "        car_dir = self.data_path / cfd_filename\n",
    "\n",
    "        stl_path = self.stl_path / f\"{car_dir.stem}.stl\"\n",
    "        info_path = self.info_path / f\"{car_dir.stem}_info.txt\"\n",
    "\n",
    "        # Read inlet velocity from info file\n",
    "        with open(info_path, \"r\") as file:\n",
    "            velocity = next(float(line.split(\":\")[1].strip()) for line in file if \"Velocity\" in line)\n",
    "            \n",
    "        air_density = self.global_params_reference[\"air_density\"]\n",
    "        # Read STL mesh\n",
    "        mesh_stl = pv.get_reader(stl_path).read()\n",
    "        stl_faces = mesh_stl.faces.reshape(-1, 4)[:, 1:]\n",
    "        stl_sizes = np.array(mesh_stl.compute_cell_sizes(length=False, area=True, volume=False).cell_data[\"Area\"])\n",
    "\n",
    "        # Read VTP surface data\n",
    "        reader = vtk.vtkXMLPolyDataReader()\n",
    "        reader.SetFileName(str(car_dir))\n",
    "        reader.Update()\n",
    "        polydata = reader.GetOutput()\n",
    "\n",
    "        celldata = get_node_to_elem(polydata).GetCellData()\n",
    "        surface_fields = np.concatenate(get_fields(celldata, self.surface_variables), axis=-1) / (air_density * velocity**2)\n",
    "\n",
    "        mesh = pv.PolyData(polydata)\n",
    "        surface_sizes = np.array(mesh.compute_cell_sizes(length=False, area=True, volume=False).cell_data[\"Area\"])\n",
    "        surface_normals = mesh.cell_normals / np.linalg.norm(mesh.cell_normals, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # Arrange global parameters reference in a list based on the type of the parameter\n",
    "        global_params_reference_list = []\n",
    "        for name, type in self.global_params_types.items():\n",
    "            if type == \"vector\":\n",
    "                global_params_reference_list.extend(self.global_params_reference[name])\n",
    "            elif type == \"scalar\":\n",
    "                global_params_reference_list.append(self.global_params_reference[name])\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Global parameter {name} not supported for  this dataset\"\n",
    "                )\n",
    "        global_params_reference = np.array(\n",
    "            global_params_reference_list, dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Prepare the list of global parameter values for each simulation file\n",
    "        global_params_values_list = []\n",
    "        for key in self.global_params_types.keys():\n",
    "            if key == \"inlet_velocity\":\n",
    "                 global_params_values_list.append(velocity)\n",
    "            elif key == \"air_density\":\n",
    "                 global_params_values_list.append(air_density)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Global parameter {key} not supported for  this dataset\"\n",
    "                )\n",
    "        global_params_values = np.array(global_params_values_list, dtype=np.float32)\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"stl_coordinates\": mesh_stl.points.astype(np.float32),\n",
    "            \"stl_centers\": mesh_stl.cell_centers().points.astype(np.float32),\n",
    "            \"stl_faces\": stl_faces.flatten().astype(np.float32),\n",
    "            \"stl_areas\": stl_sizes.astype(np.float32),\n",
    "            \"surface_mesh_centers\": mesh.cell_centers().points.astype(np.float32),\n",
    "            \"surface_normals\": surface_normals.astype(np.float32),\n",
    "            \"surface_areas\": surface_sizes.astype(np.float32),\n",
    "            \"volume_fields\": None,\n",
    "            \"volume_mesh_centers\": None,\n",
    "            \"surface_fields\": surface_fields.astype(np.float32),\n",
    "            \"filename\": cfd_filename,\n",
    "            \"global_params_values\": global_params_values,\n",
    "            \"global_params_reference\": global_params_reference,\n",
    "        }\n",
    "\n",
    "\n",
    "def process_file(fname: str, fm_data, output_path: str):\n",
    "    \"\"\"\n",
    "    Converts a single VTP/STL file into a .npy file.\n",
    "\n",
    "    Skips the file if the output already exists or if the input file is missing/empty.\n",
    "    \"\"\"\n",
    "    full_path, output_file = os.path.join(fm_data.data_path, fname), os.path.join(output_path, f\"{fname}.npy\")\n",
    "    if os.path.exists(output_file) or not os.path.exists(full_path) or os.path.getsize(full_path) == 0:\n",
    "        return\n",
    "    np.save(output_file, fm_data[fm_data.filenames.index(fname)])\n",
    "\n",
    "\n",
    "def process_surface_data_batch(dataset_paths: dict, info_paths: dict, stl_paths: dict, surface_paths: dict):\n",
    "    \"\"\"\n",
    "    Converts all surface data in the dataset into NumPy format and saves them.\n",
    "\n",
    "    Steps:\n",
    "    - Ensures output directories exist.\n",
    "    - Iterates through train/validation/test splits.\n",
    "    - Loads the dataset using OpenFoamAhmedBodySurfaceDataset.\n",
    "    - Processes files in parallel using ProcessPoolExecutor.\n",
    "    - Converts VTP+STL+global velocity into a NumPy dictionary for each case.\n",
    "    - Saves the .npy files in the corresponding prepared surface data folder.\n",
    "    \"\"\"\n",
    "    for path in surface_paths.values(): os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    print(\"=== Starting Processing ===\")\n",
    "    for key, dataset_path in dataset_paths.items():\n",
    "        surface_path = surface_paths[key]\n",
    "        os.makedirs(surface_path, exist_ok=True)\n",
    "        fm_data = OpenFoamAhmedBodySurfaceDataset(dataset_path, info_paths[key], stl_paths[key], VOLUME_VARS, SURFACE_VARS,GLOBAL_PARAMS_TYPES,GLOBAL_PARAMS_REFERENCE)\n",
    "        file_list = [fname for fname in fm_data.filenames if fname.endswith(\".vtp\")]\n",
    "\n",
    "        print(f\"\\nProcessing {len(file_list)} files from {dataset_path} → {surface_path}...\")\n",
    "\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            list(tqdm(\n",
    "                executor.map(process_file, file_list, [fm_data]*len(file_list), [surface_path]*len(file_list)),\n",
    "                total=len(file_list),\n",
    "                desc=f\"Processing {key}\",\n",
    "                dynamic_ncols=True\n",
    "            ))\n",
    "\n",
    "    print(\"=== All Processing Completed Successfully ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Processing ===\n",
      "\n",
      "Processing 408 files from /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/train → /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/train_prepared_surface_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 408/408 [00:01<00:00, 271.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 50 files from /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/validation → /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/validation_prepared_surface_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation: 100%|██████████| 50/50 [00:00<00:00, 81.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 50 files from /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/test → /workspace/physicsnemo_ahmed_body_dataset_vv1/dataset/test_prepared_surface_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test: 100%|██████████| 50/50 [00:00<00:00, 95.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Processing Completed Successfully ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_surface_data_batch(dataset_paths, info_paths, stl_paths, surface_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
